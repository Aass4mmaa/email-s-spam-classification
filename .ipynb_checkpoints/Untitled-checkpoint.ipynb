{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35109be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41dca07",
   "metadata": {},
   "source": [
    "###  Getting the email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b77ed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "listofspam=[]#list ou on va mettre tous les spam\n",
    "listofham=[]#list ou on va mettre tous les non spam\n",
    "spam=os.listdir(\"D:\\S2I M1\\S2\\AARN\\projet\\DATA\\DATA\\spam\")#list of entries in the file\n",
    "\n",
    "for i in spam :\n",
    "        try :\n",
    "            f=open(os.path.join(\"D:\\S2I M1\\S2\\AARN\\projet\\DATA\\DATA\\spam/\",i),'r', encoding='utf-8')#join pathq\n",
    "            content=f.read()\n",
    "        except UnicodeDecodeError:#if the file is code with other than utf-8\n",
    "            open(os.path.join(\"D:\\S2I M1\\S2\\AARN\\projet\\DATA\\DATA\\spam/\", i), \"r\", encoding=\"latin-1\")\n",
    "            content = f.read()\n",
    "            open(os.path.join(\"D:\\S2I M1\\S2\\AARN\\projet\\DATA\\DATA\\spam/\", i), \"w\", encoding=\"utf-8\")\n",
    "            f.write(content)\n",
    "        listofspam.append(content)\n",
    "ham=os.listdir(\"D:\\S2I M1\\S2\\AARN\\projet\\DATA\\DATA\\ham\")\n",
    "for i in ham:\n",
    "    try :\n",
    "        f=open(os.path.join(\"D:\\S2I M1\\S2\\AARN\\projet\\DATA\\DATA\\ham/\",i),'r', encoding='utf-8')\n",
    "        content=f.read()\n",
    "    except UnicodeDecodeError:\n",
    "        open(os.path.join(\"D:\\S2I M1\\S2\\AARN\\projet\\DATA\\DATA\\ham/\", i), \"r\", encoding=\"latin-1\")\n",
    "        content = f.read()\n",
    "        open(os.path.join(\"D:\\S2I M1\\S2\\AARN\\projet\\DATA\\DATA\\ham/\", i), \"w\", encoding=\"utf-8\")\n",
    "        f.write(content)\n",
    "    listofham.append(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226952ac",
   "metadata": {},
   "source": [
    "### Preparation of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "388fe87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer() \n",
    "def datapreparation(k):\n",
    "    k=k.lower()#lower case\n",
    "    k=re.sub(\"<.*?>\",\"\",k)#dropping balise html\n",
    "    k=k.replace('$','dollar')#normalizing $\n",
    "    k=re.sub('[1-9]+','nombre',k)#normalizing numbers\n",
    "    k=re.sub('(http|https)://[^\\s]+','httpaddr',k)#normalizing url\n",
    "    k=re.sub('[^\\s]+@[^\\s]+', 'emailaddr',k)#normalizing mail\n",
    "    k=k.translate(str.maketrans('', '', punctuation)) #dropping punctuations\n",
    "    k= re.sub(\"\\n\",\" \",k)#dropping line breaks\n",
    "    #lemmatization\n",
    "    for w in k:\n",
    "        if w.isalpha():\n",
    "            w=lemmatizer.lemmatize(w)\n",
    "    k=re.sub(r'\\W+',' ',k)#dropping space and other caracters\n",
    "    \n",
    "    \n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d4d88a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(listofspam)):\n",
    "    listofspam[i]=datapreparation(listofspam[i])\n",
    "for i in range(len(listofham)):\n",
    "    listofham[i]=datapreparation(listofham[i])\n",
    "#print(listofspam[0]) #to see an example \n",
    "#type(listofspam[0]) is str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e04a0db",
   "metadata": {},
   "source": [
    "### Construction du vocabulaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "899d7671",
   "metadata": {},
   "outputs": [],
   "source": [
    "#constructing a list of 10000 most common words in listofspam to work with\n",
    "def vocabulaire(l):\n",
    "    letter=Counter()\n",
    "    mat=[]\n",
    "    for i in range(len(l)):\n",
    "        mat=l[i].split()\n",
    "        letter.update(mat)\n",
    "    letter=sorted(letter, key=letter.get, reverse=True)\n",
    "    letter=letter[:10000]\n",
    "    #letter=Counter(l[0]).most_common(10000)\n",
    "    fichier=open('vocab.txt','w',encoding=\"utf-8\")\n",
    "    for i in letter:\n",
    "        fichier.writelines(i)\n",
    "        fichier.writelines(\"\\n\")\n",
    "    fichier.close()\n",
    "    return letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "443a6372",
   "metadata": {},
   "outputs": [],
   "source": [
    "voclist=vocabulaire(listofspam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3394279a",
   "metadata": {},
   "source": [
    "### Preparing our dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4af2f166",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame(listofspam,columns=['email'])\n",
    "df1['state']=1\n",
    "df2=pd.DataFrame(listofham,columns=['email'])\n",
    "df2['state']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de46db85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([df2,df1])\n",
    "df=df.sample(frac=1,random_state=123).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bff1cad",
   "metadata": {},
   "source": [
    "### Extraction of caracteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8fc3758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def caract(chaine,lis):\n",
    "    mat=np.zeros(len(lis))\n",
    "    for i in range(len(lis)):\n",
    "        if lis[i] in chaine:\n",
    "            mat[i]=1\n",
    "    return mat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec98193e",
   "metadata": {},
   "outputs": [],
   "source": [
    "array=[]\n",
    "for i in range(df.shape[0]):\n",
    "    array.append(caract(df.iloc[i,0],voclist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a375b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "email=np.array(array)\n",
    "state=df['state']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47feb18c",
   "metadata": {},
   "source": [
    "### splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf7b371",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(email,state,test_size=0.3,random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a3a688",
   "metadata": {},
   "source": [
    "###  Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ff735f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LogisticRegression()\n",
    "lr.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9eac3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('the R squared of the training data is :',lr.score(x_train,y_train))\n",
    "print('the R squared of the testing data is :',lr.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b75acca",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
